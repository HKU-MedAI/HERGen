{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from hergen.utils.constants import CHEXPERT_COMPETITION_TASKS, CHEXPERT_TASKS, CHEXPERT_UNCERTAIN_MAPPINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change your path here:\n",
    "mimic_dir = \"/data1/r20user2/CXR_dataset/mimic_data/2.0.0\"\n",
    "mimic_annotation_dir = \"/data1/r20user2/CXR_dataset/knowledge_graph\"\n",
    "mimic_img_dir = os.path.join(mimic_dir, \"files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.read_csv(os.path.join(mimic_dir, \"master.csv\"))\n",
    "# keep one image one study\n",
    "# master_df.drop_duplicates(subset=[\"subject_id\", \"study_id\"], inplace=True)\n",
    "\n",
    "chexpert_df = pd.read_csv(os.path.join(mimic_dir, \"mimic-cxr-2.0.0-chexpert.csv\"))\n",
    "chexpert_df.fillna(0, inplace=True)\n",
    "\n",
    "master_df[\"report\"] = master_df[\"impression\"] + \" \" + master_df[\"findings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 232421 entries, 0 to 232420\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Path          232421 non-null  object \n",
      " 1   dicom_id      232421 non-null  object \n",
      " 2   subject_id    232421 non-null  int64  \n",
      " 3   study_id      232421 non-null  object \n",
      " 4   ViewPosition  232421 non-null  object \n",
      " 5   StudyDate     232421 non-null  int64  \n",
      " 6   StudyTime     232421 non-null  float64\n",
      " 7   impression    232421 non-null  object \n",
      " 8   findings      232421 non-null  object \n",
      " 9   split         232421 non-null  object \n",
      " 10  report        232421 non-null  object \n",
      "dtypes: float64(1), int64(2), object(8)\n",
      "memory usage: 19.5+ MB\n"
     ]
    }
   ],
   "source": [
    "master_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "train    227459\n",
       "test       3082\n",
       "valid      1880\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df[\"split\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # only use training set\n",
    "# split = \"train\"\n",
    "# split_df = master_df[master_df[\"split\"] == split]\n",
    "# split_df[\"imgpath\"] = split_df[\"Path\"].apply(lambda x: os.path.join(mimic_img_dir, x))\n",
    "# split_df[\"study_id\"] = split_df[\"study_id\"].apply(lambda x: int(x[1:]))\n",
    "\n",
    "master_df[\"study_id\"] = master_df[\"study_id\"].apply(lambda x: int(x[1:]))\n",
    "merged_df = pd.merge(master_df, chexpert_df, how=\"left\", on=[\"subject_id\", \"study_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 232421 entries, 0 to 232420\n",
      "Data columns (total 25 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   Path                        232421 non-null  object \n",
      " 1   dicom_id                    232421 non-null  object \n",
      " 2   subject_id                  232421 non-null  int64  \n",
      " 3   study_id                    232421 non-null  int64  \n",
      " 4   ViewPosition                232421 non-null  object \n",
      " 5   StudyDate                   232421 non-null  int64  \n",
      " 6   StudyTime                   232421 non-null  float64\n",
      " 7   impression                  232421 non-null  object \n",
      " 8   findings                    232421 non-null  object \n",
      " 9   split                       232421 non-null  object \n",
      " 10  report                      232421 non-null  object \n",
      " 11  Atelectasis                 232421 non-null  float64\n",
      " 12  Cardiomegaly                232421 non-null  float64\n",
      " 13  Consolidation               232421 non-null  float64\n",
      " 14  Edema                       232421 non-null  float64\n",
      " 15  Enlarged Cardiomediastinum  232421 non-null  float64\n",
      " 16  Fracture                    232421 non-null  float64\n",
      " 17  Lung Lesion                 232421 non-null  float64\n",
      " 18  Lung Opacity                232421 non-null  float64\n",
      " 19  No Finding                  232421 non-null  float64\n",
      " 20  Pleural Effusion            232421 non-null  float64\n",
      " 21  Pleural Other               232421 non-null  float64\n",
      " 22  Pneumonia                   232421 non-null  float64\n",
      " 23  Pneumothorax                232421 non-null  float64\n",
      " 24  Support Devices             232421 non-null  float64\n",
      "dtypes: float64(15), int64(3), object(7)\n",
      "memory usage: 44.3+ MB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232421, 25)\n",
      "(231421, 25)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "train_df = merged_df.loc[merged_df[\"split\"] == \"train\"]\n",
    "print(merged_df.shape)\n",
    "\n",
    "task_dfs = []\n",
    "for i, t in enumerate(CHEXPERT_COMPETITION_TASKS):\n",
    "    index = np.zeros(14)\n",
    "    index[i] = 1\n",
    "    df_task = train_df[\n",
    "        (train_df[\"Atelectasis\"] == index[0])\n",
    "        & (train_df[\"Cardiomegaly\"] == index[1])\n",
    "        & (train_df[\"Consolidation\"] == index[2])\n",
    "        & (train_df[\"Edema\"] == index[3])\n",
    "        & (train_df[\"Pleural Effusion\"] == index[4])\n",
    "        & (train_df[\"Enlarged Cardiomediastinum\"] == index[5])\n",
    "        & (train_df[\"Lung Lesion\"] == index[7])\n",
    "        & (train_df[\"Lung Opacity\"] == index[8])\n",
    "        & (train_df[\"Pneumonia\"] == index[9])\n",
    "        & (train_df[\"Pneumothorax\"] == index[10])\n",
    "        & (train_df[\"Pleural Other\"] == index[11])\n",
    "        & (train_df[\"Fracture\"] == index[12])\n",
    "        & (train_df[\"Support Devices\"] == index[13])\n",
    "    ]\n",
    "    df_task = df_task.sample(n=200, random_state=42)\n",
    "    task_dfs.append(df_task)\n",
    "df_200 = pd.concat(task_dfs)\n",
    "\n",
    "mimic_df_200 = df_200[[\"subject_id\", \"study_id\", \"dicom_id\", \"ViewPosition\", \"report\"] + CHEXPERT_TASKS]\n",
    "mimic_df_200.to_csv(\"mimic-cxr-5x200-val-meta.csv\", index=False)\n",
    "\n",
    "merged_df = merged_df[~merged_df[\"Path\"].isin(df_200[\"Path\"])]\n",
    "print(merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_file = os.path.join(mimic_annotation_dir, \"mimic_annotation.json\")\n",
    "\n",
    "with open(annotation_file) as f:\n",
    "    all_examples = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3858"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_examples[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.loc[:, [\"dicom_id\", \"ViewPosition\", \"StudyDate\", \"StudyTime\", \"split\"] + CHEXPERT_TASKS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 231421 entries, 0 to 232420\n",
      "Data columns (total 19 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   dicom_id                    231421 non-null  object \n",
      " 1   ViewPosition                231421 non-null  object \n",
      " 2   StudyDate                   231421 non-null  int64  \n",
      " 3   StudyTime                   231421 non-null  float64\n",
      " 4   split                       231421 non-null  object \n",
      " 5   No Finding                  231421 non-null  float64\n",
      " 6   Enlarged Cardiomediastinum  231421 non-null  float64\n",
      " 7   Cardiomegaly                231421 non-null  float64\n",
      " 8   Lung Lesion                 231421 non-null  float64\n",
      " 9   Lung Opacity                231421 non-null  float64\n",
      " 10  Edema                       231421 non-null  float64\n",
      " 11  Consolidation               231421 non-null  float64\n",
      " 12  Pneumonia                   231421 non-null  float64\n",
      " 13  Atelectasis                 231421 non-null  float64\n",
      " 14  Pneumothorax                231421 non-null  float64\n",
      " 15  Pleural Effusion            231421 non-null  float64\n",
      " 16  Pleural Other               231421 non-null  float64\n",
      " 17  Fracture                    231421 non-null  float64\n",
      " 18  Support Devices             231421 non-null  float64\n",
      "dtypes: float64(15), int64(1), object(3)\n",
      "memory usage: 35.3+ MB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "train    226459\n",
       "test       3082\n",
       "valid      1880\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[\"split\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"split\"] = merged_df[\"split\"].replace({\"valid\": \"val\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 231421 entries, 0 to 232420\n",
      "Data columns (total 19 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   dicom_id                    231421 non-null  object \n",
      " 1   ViewPosition                231421 non-null  object \n",
      " 2   StudyDate                   231421 non-null  int64  \n",
      " 3   StudyTime                   231421 non-null  float64\n",
      " 4   split                       231421 non-null  object \n",
      " 5   No Finding                  231421 non-null  float64\n",
      " 6   Enlarged Cardiomediastinum  231421 non-null  float64\n",
      " 7   Cardiomegaly                231421 non-null  float64\n",
      " 8   Lung Lesion                 231421 non-null  float64\n",
      " 9   Lung Opacity                231421 non-null  float64\n",
      " 10  Edema                       231421 non-null  float64\n",
      " 11  Consolidation               231421 non-null  float64\n",
      " 12  Pneumonia                   231421 non-null  float64\n",
      " 13  Atelectasis                 231421 non-null  float64\n",
      " 14  Pneumothorax                231421 non-null  float64\n",
      " 15  Pleural Effusion            231421 non-null  float64\n",
      " 16  Pleural Other               231421 non-null  float64\n",
      " 17  Fracture                    231421 non-null  float64\n",
      " 18  Support Devices             231421 non-null  float64\n",
      "dtypes: float64(15), int64(1), object(3)\n",
      "memory usage: 35.3+ MB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "270790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3563580/1487327455.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  split_df.drop(columns=[\"split\"], inplace=True)\n",
      "/tmp/ipykernel_3563580/1487327455.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  frontal_df.drop(columns=[\"dicom_id\"], inplace=True)\n",
      "/tmp/ipykernel_3563580/1487327455.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  frontal_df.drop_duplicates(subset=[\"subject_id\", \"study_id\", \"report\"], inplace=True)\n",
      "/tmp/ipykernel_3563580/1487327455.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  frontal_df.sort_values(by=[\"subject_id\", \"StudyDate\", \"StudyTime\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145471\n",
      "val\n",
      "2130\n",
      "1151\n",
      "test\n",
      "3858\n",
      "2210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3563580/1487327455.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  split_df.drop(columns=[\"split\"], inplace=True)\n",
      "/tmp/ipykernel_3563580/1487327455.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  frontal_df.drop(columns=[\"dicom_id\"], inplace=True)\n",
      "/tmp/ipykernel_3563580/1487327455.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  frontal_df.drop_duplicates(subset=[\"subject_id\", \"study_id\", \"report\"], inplace=True)\n",
      "/tmp/ipykernel_3563580/1487327455.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  frontal_df.sort_values(by=[\"subject_id\", \"StudyDate\", \"StudyTime\"], inplace=True)\n",
      "/tmp/ipykernel_3563580/1487327455.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  split_df.drop(columns=[\"split\"], inplace=True)\n",
      "/tmp/ipykernel_3563580/1487327455.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  frontal_df.drop(columns=[\"dicom_id\"], inplace=True)\n",
      "/tmp/ipykernel_3563580/1487327455.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  frontal_df.drop_duplicates(subset=[\"subject_id\", \"study_id\", \"report\"], inplace=True)\n",
      "/tmp/ipykernel_3563580/1487327455.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  frontal_df.sort_values(by=[\"subject_id\", \"StudyDate\", \"StudyTime\"], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "new_dataset_ds = dict()\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    print(split)\n",
    "    \n",
    "    examples = all_examples[split]\n",
    "    print(len(examples))\n",
    "    dataset_as_dfs = pd.DataFrame(examples)\n",
    "\n",
    "    split_df = merged_df[merged_df[\"split\"] == split]\n",
    "    split_df.drop(columns=[\"split\"], inplace=True)\n",
    "\n",
    "    # merge json with metadata\n",
    "    df = pd.merge(dataset_as_dfs, split_df, left_on=\"id\", right_on=\"dicom_id\", how=\"left\")\n",
    "    # only keep frontal view\n",
    "    frontal_df = df.loc[df[\"ViewPosition\"].isin([\"PA\", \"AP\"])]\n",
    "    \n",
    "    frontal_df.drop(columns=[\"dicom_id\"], inplace=True)\n",
    "    frontal_df.drop_duplicates(subset=[\"subject_id\", \"study_id\", \"report\"], inplace=True)\n",
    "    frontal_df.sort_values(by=[\"subject_id\", \"StudyDate\", \"StudyTime\"], inplace=True)\n",
    "    frontal_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    new_dataset_ds[split] = frontal_df.to_dict(\"records\")\n",
    "    print(len(frontal_df))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_cxr_dir = os.path.join(mimic_annotation_dir, \"../temporal_CXR\")\n",
    "os.makedirs(temporal_cxr_dir, exist_ok=True)\n",
    "with open(os.path.join(temporal_cxr_dir, \"mimic_annotation.json\"), \"w\") as f:\n",
    "    json.dump(new_dataset_ds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of original train: 145471\n",
      "Number of temporal train: 111750\n",
      "Number of original val: 1151\n",
      "Number of temporal val: 897\n",
      "Number of original test: 2210\n",
      "Number of temporal test: 2183\n"
     ]
    }
   ],
   "source": [
    "temporal_dataset_ds = dict()\n",
    "for split in new_dataset_ds.keys():\n",
    "    examples = new_dataset_ds[split]\n",
    "    dataset_as_dfs = pd.DataFrame(examples)\n",
    "    print(f\"Number of original {split}: {len(dataset_as_dfs)}\")\n",
    "\n",
    "    subject_cnts = dataset_as_dfs[\"subject_id\"].value_counts()\n",
    "    # only keep subjects with at least 2 images\n",
    "    cur_subject_cnts = subject_cnts[subject_cnts >= 2]\n",
    "    dataset_as_dfs = dataset_as_dfs.loc[dataset_as_dfs[\"subject_id\"].isin(\n",
    "        cur_subject_cnts.index.tolist())]\n",
    "    \n",
    "    temporal_dataset_ds[split] = dataset_as_dfs.to_dict(\"records\")\n",
    "    print(f\"Number of temporal {split}: {len(dataset_as_dfs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(temporal_cxr_dir, \"longitudinal_mimic_annotation.json\"), \"w\") as f:\n",
    "    json.dump(temporal_dataset_ds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seqmae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
